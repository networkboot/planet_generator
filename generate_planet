#!/usr/bin/env perl

use strict;
use warnings;
use autodie;
use feature qw(say);

use Text::CSV;
use XML::Feed;
use URI;
use LWP::Protocol::https;
use DateTime;
use Regexp::Assemble;
use File::Slurp qw(write_file);

my $work_dir = 'work';

my $csv_file = 'feeds.csv';
my $csv_site_url_column = 'site_url';
my $csv_feed_url_column = 'feed_url';
my $csv_author_column   = 'author';
my $csv_id_column       = 'md5';

my @keywords = (
    'networkboot.org',
    'network boot',
    'network booting',
    qw(
        PXE netboot
        iPXE gPXE Etherboot
        DHCP BOOTP TFTP
        iSCSI NFS AoE
        grub
        PXELinux SYSLinux
    )
);
my $agg_feed_title = 'Blog posts related to network booting';
my $agg_feed_author = 'NetworkBoot.org';
my $agg_feed_link = 'http://networkboot.org/planet/';
my $agg_feed_file = 'planet.xml';

my $keyword_re = build_keyword_re(@keywords);

chdir $work_dir;

# Extract blog URLs from CSV
my @contributors = get_contributors_from_csv();
# Fetch feeds
my @feeds = fetch_feeds(@contributors);
# Print feeds
say join("\n",
    map { $_->link . ':' . $_->title . ' (' . $_->format . ')' }
    @feeds
);
# Get all feed entries in chronological order, newest first
my @entries = extract_entries(@feeds);
# Print all entries
#while ( my $entry = shift @entries ) {
#    say $entry->issued . ': ' . $entry->title . ' by ' . $entry->author;
#    say "\t" . $entry->link;
#}
# Generate aggregate feed of all entries
my $feed = create_aggregate_feed(@entries);
# Create aggregate feed
say "Writing aggregate feed $agg_feed_file...";
write_file($agg_feed_file, { binmode => ':raw' }, $feed->as_xml);

exit;

############################

sub get_contributors_from_csv {
    say "Extracting contributors from CSV...";
    my $csv = Text::CSV->new({
        'sep_char' => ';',
        'auto_diag' => 1,
        'binary' => 1,
    });
    open my $csv_fh, '<', $csv_file;
    my @columns = @{ $csv->getline($csv_fh) };
    $csv->column_names(@columns);
    my @contributors;
    while ( my $row = $csv->getline_hr($csv_fh) ) {
        push @contributors, {
            'site_url' => $row->{ $csv_site_url_column },
            'feed_url' => $row->{ $csv_feed_url_column },
            'author'   => $row->{ $csv_author_column   },
            'id'       => $row->{ $csv_id_column       },
        };
    }
    close $csv_fh;
    return @contributors;
}

sub fetch_feeds {
    my (@contributors) = @_;
    say "Fetching feeds...";
    my @feeds;
    while ( my $contributor = shift @contributors) {
        my $site_url = $contributor->{'site_url'};
        my $feed_url = $contributor->{'feed_url'};
        my $author   = $contributor->{'author'};
        next unless $feed_url;
        say "Fetching $feed_url...";
        my $feed = XML::Feed->parse( URI->new($feed_url) );
        say "\tUnable to find $feed_url" unless $feed;
        say "\tError occured: " . XML::Feed->error if XML::Feed->error;
        next unless $feed;
        say "\tFeed title: " . $feed->title . " (" . $feed->format . ")";
        # Convert it to Atom, if needed
        $feed = $feed->convert('Atom') unless $feed->format =~ m/Atom/;
        # Add some metadata
        $feed->link(      $site_url ) if $site_url;
        $feed->self_link( $feed_url ) if $feed_url;
        $feed->author(    $author   ) if $author;
        push @feeds, $feed;
    }
    return @feeds;
}

sub extract_entries {
    my (@feeds) = @_;
    my @entries;
    while ( my $feed = shift @feeds ) {
        next unless $feed;
        my @items = $feed->entries;
        while ( my $entry = shift @items ) {
            next unless $entry;
            next unless $entry->issued;
            $entry->author( $feed->author );
            $entry->base(   $feed->base   ) unless $entry->base;
            push @entries, $entry;
        }
    }
    # Return entries filtered and sorted, newest first
    return reverse
           sort { DateTime->compare($a->issued, $b->issued) }
           grep { defined }
           map { filter_entry($_) }
           @entries;
}

# Make sure the textual parts of a feed entry matches the keywords
sub filter_entry {
    my ($entry) = @_;
    return unless defined $entry;
    return $entry unless $entry->can('title');
    return $entry unless $entry->can('content');
    return $entry unless $entry->can('summary');
    return $entry unless $entry->can('category');
    my $text = join("\n",
        grep { defined }
        $entry->title,
        $entry->category, # might be multiple
        ( $entry->summary && $entry->summary->body ),
        ( $entry->content && $entry->content->body ),
    );
    # Put name of author in title, if present
    $entry->title( $entry->author . ': ' . $entry->title ) if $entry->author;
    return $entry if $text =~ m/$keyword_re/i;
    return;
}

sub build_keyword_re {
    my (@keywords) = @_;
    my $ra = Regexp::Assemble->new();
    while ( my $keyword = shift @keywords ) {
        my $re = qr/\Q$keyword\E/;
        $ra->add($re);
    }
    return $ra->re;
}

sub create_aggregate_feed {
    my (@entries) = @_;
    my $feed = XML::Feed->new('Atom');
    $feed->author( $agg_feed_author );
    $feed->link(   $agg_feed_link   );
    $feed->title(  $agg_feed_title  );
    $feed->add_entry($_) for @entries;
    return $feed;
}
