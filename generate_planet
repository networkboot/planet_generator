#!/usr/bin/env perl

use strict;
use warnings;
use autodie;
use feature qw(say);

use Text::CSV;
use XML::Feed;
use URI;
use LWP::Protocol::https;
use DateTime;
use Regexp::Assemble;
use File::Slurp qw(write_file);

my $work_dir = 'work';
my $csv_url = 'http://networkboot.org/planet/blogs.csv';
my $csv_file = 'blogs.csv';
my $csv_site_url_column = 'site';
my $csv_author_column = 'owner';
my @keywords = (
    'networkboot.org',
    'network boot',
    'network booting',
    qw(
        PXE netboot
        iPXE gPXE Etherboot
        DHCP BOOTP TFTP
        iSCSI NFS AoE
        grub
        PXELinux SYSLinux
    )
);
my $agg_feed_title = 'Blog posts related to network booting';
my $agg_feed_author = 'NetworkBoot.org';
my $agg_feed_link = 'http://networkboot.org/planet/';
my $agg_feed_file = 'planet.xml';

my $keyword_re = build_keyword_re(@keywords);

chdir $work_dir;

# Fetch blogs.csv
fetch_csv();
# Extract blog URLs from CSV
my @urls = get_blog_urls_from_csv();
# Fetch feeds
my @feeds = fetch_feeds(@urls);
# Print feeds
#say join("\n",
#    map { $_->link . ':' . $_->title . ' (' . $_->format . ')' }
#    @feeds
#);
# Get all feed entries in chronological order, newest first
my @entries = extract_entries(@feeds);
# Print all entries
#while ( my $entry = shift @entries ) {
#    say $entry->issued . ': ' . $entry->title . ' by ' . $entry->author;
#    say "\t" . $entry->link;
#}
# Generate aggregate feed of all entries
my $feed = create_aggregate_feed(@entries);
# Create aggregate feed
say "Writing aggregate feed $agg_feed_file...";
write_file($agg_feed_file, { binmode => ':raw' }, $feed->as_xml);

exit;

############################

sub fetch_csv {
    say "Fetching $csv_url...";
    system(qw(wget -q -O), $csv_file, $csv_url);
}

sub get_blog_urls_from_csv {
    say "Extracting blog URLs from CSV...";
    my $csv = Text::CSV->new({
        'sep_char' => ';',
        'auto_diag' => 1,
        'binary' => 1,
    });
    open my $csv_fh, '<', $csv_file;
    my @columns = @{ $csv->getline($csv_fh) };
    $csv->column_names(@columns);
    my @urls;
    while ( my $row = $csv->getline_hr($csv_fh) ) {
        push @urls, [
            $row->{ $csv_site_url_column },
            $row->{ $csv_author_column }
        ];
    }
    close $csv_fh;
    return @urls;
}

sub fetch_feeds {
    my (@urls) = @_;
    say "Fetching feeds...";
    my @feeds;
    while ( my $url = shift @urls) {
        my $author;
        if ( ref($url) eq ref([]) ) {
            $author = $url->[1];
            $url = $url->[0];
        }
        say "Finding feeds for $url...";
        my @feed_urls = XML::Feed->find_feeds($url);
        unless ( @feed_urls ) {
            say "\tNo feeds found for $url: " . ( XML::Feed->error || "" );
            next;
        }
        my @candidate_feeds;
        foreach my $feed_url ( @feed_urls ) {
            $feed_url = URI->new($feed_url);
            if ( $feed_url =~ m/comment/i ) {
                say "\tSkipped $feed_url...";
                next;
            }
            say "\tFetching $feed_url...";
            my $feed = XML::Feed->parse( $feed_url );
            unless ( $feed ) {
                say "\tFetching $feed_url failed: " . ( XML::Feed->error || "" );
                next;
            }
            if ( $feed->title =~ m/comment/i ) {
                say "\tSkipped $feed_url (" . $feed->title . ")";
                next;
            }
            say "\tFeed title: " . $feed->title . " (" . $feed->format . ")";
            # Put Atom feeds at start of stack
            if ( $feed->format =~ m/Atom/ ) {
                unshift @candidate_feeds, [ $feed, $feed_url ];
                next;
            }
            # Other feeds go at the end of the stack
            push @candidate_feeds, [ $feed, $feed_url ];
        }
        # Get first candidate feed
        my $feed_info = shift @candidate_feeds;
        next unless $feed_info;
        my $feed = $feed_info->[0];
        my $feed_url = $feed_info->[1];
        # Make sure it is valid
        next unless $feed;
        # Convert it to Atom
        $feed = $feed->convert('Atom') unless $feed->format =~ m/Atom/;
        # Fix missing links in channel information
        $feed->link( $url )           unless $feed->link;
        $feed->self_link( $feed_url ) unless $feed->self_link;
        if ( $author ) {
            $feed->author( $author ); # unless $feed->author;
        }
        push @feeds, $feed;
    }
    return @feeds;
}

sub extract_entries {
    my (@feeds) = @_;
    my @entries;
    while ( my $feed = shift @feeds ) {
        next unless $feed;
        my @items = $feed->entries;
        while ( my $entry = shift @items ) {
            next unless $entry;
            next unless $entry->issued;
            $entry->author( $feed->author ); # unless $entry->author;
            $entry->base(   $feed->base   ) unless $entry->base;
            push @entries, $entry;
        }
    }
    # Return entries filtered and sorted, newest first
    return reverse
           sort { DateTime->compare($a->issued, $b->issued) }
           grep { defined }
           map { filter_entry($_) }
           @entries;
}

# Make sure the textual parts of a feed entry matches the keywords
sub filter_entry {
    my ($entry) = @_;
    return unless defined $entry;
    return $entry unless $entry->can('title');
    return $entry unless $entry->can('content');
    return $entry unless $entry->can('summary');
    return $entry unless $entry->can('category');
    my $text = join("\n",
        grep { defined }
        $entry->title,
        $entry->category, # might be multiple
        ( $entry->summary && $entry->summary->body ),
        ( $entry->content && $entry->content->body ),
    );
    # Put name of author in title, if present
    $entry->title( $entry->author . ': ' . $entry->title ) if $entry->author;
    return $entry if $text =~ m/$keyword_re/i;
    return;
}

sub build_keyword_re {
    my (@keywords) = @_;
    my $ra = Regexp::Assemble->new();
    while ( my $keyword = shift @keywords ) {
        my $re = qr/\Q$keyword\E/;
        $ra->add($re);
    }
    return $ra->re;
}

sub create_aggregate_feed {
    my (@entries) = @_;
    my $feed = XML::Feed->new('Atom');
    $feed->author( $agg_feed_author );
    $feed->link(   $agg_feed_link   );
    $feed->title(  $agg_feed_title  );
    $feed->add_entry($_) for @entries;
    return $feed;
}
